# scripts/sync_disclosure_data.py (ä¿®å¤ç‰ˆ)

import time
from datetime import datetime, timedelta

import akshare as ak
import pandas as pd
from sqlalchemy import Index
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker

from db.database import get_engine_instance
from db.models import StockList, StockDisclosure

# --- é…ç½® ---
engine = get_engine_instance()
Session = sessionmaker(bind=engine)
pd.options.mode.chained_assignment = None  # å¿½ç•¥pandasçš„é“¾å¼èµ‹å€¼è­¦å‘Š


# --- è¾…åŠ©å‡½æ•° ---
def get_stock_pool() -> pd.DataFrame:
    session = Session()
    df = pd.read_sql("SELECT code AS symbol, list_date FROM stock_list", con=engine)
    session.close()
    return df


def get_last_disclosure_date(symbol: str) -> datetime.date:
    session = Session()
    last = (
        session.query(StockDisclosure)
        .filter_by(symbol=symbol)
        .order_by(StockDisclosure.ann_date.desc())
        .first()
    )
    session.close()
    return last.ann_date if last else None


def fetch_all_disclosures(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ã€æœ€ç»ˆä¿®å¤ç‰ˆã€‘ç‹¬ç«‹å¤„ç†æ¯ä¸ªAPIè°ƒç”¨ï¼Œä½¿å…¶èƒ½æŠµæŠ—å•ä¸ªæ¥å£çš„å¤±è´¥ã€‚
    """
    all_dfs = []  # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥å­˜æ”¾æ‰€æœ‰æˆåŠŸè·å–çš„DataFrame

    # --- 1. è·å–å¸¸è§„æŠ¥å‘Šï¼Œç”¨ç‹¬ç«‹çš„ try-except åŒ…è£¹ ---
    try:
        df_reports = ak.stock_zh_a_disclosure_report_cninfo(symbol=symbol, start_date=start_date, end_date=end_date)
        if df_reports is not None and not df_reports.empty:
            all_dfs.append(df_reports)
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Šï¼šæ‹‰å– {symbol} [å¸¸è§„æŠ¥å‘Š] æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ä¿¡æ¯: {e}")

    time.sleep(0.3)  # ä¿æŒä¼‘çœ 

    # --- 2. è·å–è°ƒç ”å…¬å‘Šï¼Œç”¨ç‹¬ç«‹çš„ try-except åŒ…è£¹ ---
    try:
        df_relations = ak.stock_zh_a_disclosure_relation_cninfo(symbol=symbol, start_date=start_date, end_date=end_date)
        if df_relations is not None and not df_relations.empty:
            df_relations['tag'] = 'è°ƒç ”æ´»åŠ¨'
            all_dfs.append(df_relations)
    except Exception as e:
        # è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„ä¸»è¦é—®é¢˜ç‚¹ï¼Œç°åœ¨å®ƒå¯ä»¥è¢«å®‰å…¨åœ°æ•è·è€Œä¸ä¼šä¸­æ–­æ•´ä¸ªæµç¨‹
        print(f"âš ï¸  è­¦å‘Šï¼šæ‹‰å– {symbol} [è°ƒç ”å…¬å‘Š] æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ä¿¡æ¯: {e}")

    # --- 3. å¦‚æœä¸¤ä¸ªæ¥å£éƒ½å¤±è´¥æˆ–æ²¡æ•°æ®ï¼Œåˆ™è¿”å› None ---
    if not all_dfs:
        return None

    # --- 4. åˆå¹¶æ‰€æœ‰æˆåŠŸè·å–çš„æ•°æ® ---
    combined_df = pd.concat(all_dfs, ignore_index=True)
    if combined_df.empty:
        return None

    combined_df.drop_duplicates(subset=['å…¬å‘Šé“¾æ¥'], keep='first', inplace=True)

    # --- 5. æ ‡å‡†åŒ–å¤„ç† (ä½¿ç”¨"å…¬å‘Šæ—¶é—´"ï¼Œå› ä¸ºè¯Šæ–­ç»“æœè¯æ˜äº†å®ƒæ˜¯æ­£ç¡®çš„åˆ—å) ---
    combined_df.rename(columns={
        "ä»£ç ": "symbol",
        "ç®€ç§°": "short_name",
        "å…¬å‘Šæ ‡é¢˜": "title",
        "å…¬å‘Šæ—¶é—´": "ann_date",  # ä½¿ç”¨è¯Šæ–­æ¢é’ˆç¡®è®¤çš„æ­£ç¡®åˆ—å
        "å…¬å‘Šé“¾æ¥": "url",
    }, inplace=True)

    combined_df["symbol"] = combined_df["symbol"].astype(str)
    # ä½¿ç”¨ format='mixed' æ¥çµæ´»å¤„ç† "YYYY-MM-DD" å’Œ "YYYY-MM-DD HH:MM:SS" ä¸¤ç§æ ¼å¼
    combined_df["ann_date"] = pd.to_datetime(combined_df["ann_date"], format='mixed').dt.date

    final_columns = ["symbol", "short_name", "title", "ann_date", "url"]
    return combined_df.reindex(columns=final_columns)

# --- ä¸»æµç¨‹ (æ›´æ–°ä»¥ä½¿ç”¨ä¿®å¤åçš„å‡½æ•°) ---
def sync_all_disclosures():
    stock_df = get_stock_pool()
    today_str = datetime.now().strftime("%Y%m%d")
    print(f"ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰ç±»å‹å…¬å‘Šï¼Œå…± {len(stock_df)} åªè‚¡ç¥¨ï¼Œæˆªæ­¢æ—¥æœŸï¼š{today_str}")

    session = Session() # åœ¨å¾ªç¯å¤–åˆ›å»º Sessionï¼Œæé«˜æ•ˆç‡
    try:
        for idx, row in stock_df.iterrows():
            symbol = row["symbol"]
            list_date = row["list_date"]
            
            # ä½¿ç”¨å½“å‰ä¼šè¯æŸ¥è¯¢
            last_record = (
                session.query(StockDisclosure)
                .filter_by(symbol=symbol)
                .order_by(StockDisclosure.ann_date.desc())
                .first()
            )
            last_date = last_record.ann_date if last_record else None

            if last_date:
                # æ–°é€»è¾‘ï¼šåˆ é™¤æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ï¼Œä»¥ä¾¿é‡æ–°è·å–å½“å¤©çš„å…¨éƒ¨å…¬å‘Š
                print(f"â„¹ï¸  ä¸ºç¡®ä¿æ•°æ®å®Œæ•´æ€§ï¼Œæ­£åœ¨åˆ é™¤ {symbol} åœ¨ {last_date} çš„æ—§å…¬å‘Š...")
                session.query(StockDisclosure).filter(
                    StockDisclosure.symbol == symbol,
                    StockDisclosure.ann_date == last_date
                ).delete(synchronize_session=False)
                session.commit() # ç«‹å³æäº¤åˆ é™¤æ“ä½œ
                
                # ä»è¢«åˆ é™¤çš„æ—¥æœŸå¼€å§‹é‡æ–°çˆ¬å–
                start_date = last_date.strftime("%Y%m%d")
            else:
                # å¯¹äºæ–°è‚¡ç¥¨ï¼Œä»ä¸Šå¸‚æ—¥æœŸå¼€å§‹
                start_date = pd.to_datetime(list_date).strftime("%Y%m%d") if list_date else "20100101"

            if start_date > today_str:
                print(f"â­ï¸ {symbol} æ— éœ€æ›´æ–°")
                continue

            print(f"â¬‡ï¸ [{idx + 1}/{len(stock_df)}] {symbol} ä» {start_date} æ›´æ–°è‡³ {today_str}")

            # ä½¿ç”¨ç»Ÿä¸€çš„è·å–å‡½æ•°
            df_new = fetch_all_disclosures(symbol, start_date, today_str)

            if df_new is None or df_new.empty:
                print(f"âšªï¸ {symbol} åœ¨æ­¤æœŸé—´æ— æ–°å…¬å‘Šã€‚")
                time.sleep(1) # ä¿æŒé€‚å½“çš„å»¶è¿Ÿ
                continue

            # åŒé‡ä¿é™©ï¼šåœ¨å†™å…¥å‰ï¼Œå…ˆæŸ¥è¯¢å¹¶æ’é™¤æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„URL
            new_urls = df_new['url'].tolist()
            existing_urls_query = session.query(StockDisclosure.url).filter(StockDisclosure.url.in_(new_urls))
            existing_urls = {url for url, in existing_urls_query}
            
            final_df = df_new[~df_new['url'].isin(existing_urls)]

            if final_df.empty:
                print(f"â„¹ï¸ {symbol} è·å–åˆ°çš„å…¬å‘Šå‡å·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼Œæ— éœ€å†™å…¥ã€‚")
                time.sleep(1)
                continue

            try:
                final_df.to_sql("stock_disclosure", con=engine, index=False, if_exists="append")
                print(f"âœ… {symbol} æˆåŠŸå†™å…¥ {len(final_df)} æ¡æ–°å…¬å‘Šã€‚")
            except Exception as e:
                # ç§»é™¤äº†å¯¹ IntegrityError çš„æ•è·ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ä¸»åŠ¨å»é‡
                print(f"âŒ {symbol} å†™å…¥æ•°æ®åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

            time.sleep(1)
    finally:
        session.close() # ç¡®ä¿ä¼šè¯è¢«å…³é—­

    print("ğŸ­ ç¡®ä¿ç´¢å¼•å·²åˆ›å»º...")
    Index("idx_disclosure_date", StockDisclosure.ann_date).create(bind=engine, checkfirst=True)
    Index("idx_disclosure_symbol", StockDisclosure.symbol).create(bind=engine, checkfirst=True)
    print("ğŸ‰ æ‰€æœ‰å…¬å‘ŠåŒæ­¥å®Œæˆï¼")


if __name__ == "__main__":
    sync_all_disclosures()