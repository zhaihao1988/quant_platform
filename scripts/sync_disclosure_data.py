# scripts/sync_disclosure_data.py (ä¿®å¤ç‰ˆ)

import time
from datetime import datetime, timedelta

import akshare as ak
import pandas as pd
from sqlalchemy import Index
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import sessionmaker

from db.database import get_engine_instance
from db.models import StockList, StockDisclosure

# --- é…ç½® ---
engine = get_engine_instance()
Session = sessionmaker(bind=engine)
pd.options.mode.chained_assignment = None  # å¿½ç•¥pandasçš„é“¾å¼èµ‹å€¼è­¦å‘Š


# --- è¾…åŠ©å‡½æ•° ---
def get_stock_pool() -> pd.DataFrame:
    session = Session()
    df = pd.read_sql("SELECT code AS symbol, list_date FROM stock_list", con=engine)
    session.close()
    return df


def get_last_disclosure_date(symbol: str) -> datetime.date:
    session = Session()
    last = (
        session.query(StockDisclosure)
        .filter_by(symbol=symbol)
        .order_by(StockDisclosure.ann_date.desc())
        .first()
    )
    session.close()
    return last.ann_date if last else None


def fetch_all_disclosures(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ã€æœ€ç»ˆä¿®å¤ç‰ˆã€‘ç‹¬ç«‹å¤„ç†æ¯ä¸ªAPIè°ƒç”¨ï¼Œä½¿å…¶èƒ½æŠµæŠ—å•ä¸ªæ¥å£çš„å¤±è´¥ã€‚
    """
    all_dfs = []  # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥å­˜æ”¾æ‰€æœ‰æˆåŠŸè·å–çš„DataFrame

    # --- 1. è·å–å¸¸è§„æŠ¥å‘Šï¼Œç”¨ç‹¬ç«‹çš„ try-except åŒ…è£¹ ---
    try:
        df_reports = ak.stock_zh_a_disclosure_report_cninfo(symbol=symbol, start_date=start_date, end_date=end_date)
        if df_reports is not None and not df_reports.empty:
            all_dfs.append(df_reports)
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Šï¼šæ‹‰å– {symbol} [å¸¸è§„æŠ¥å‘Š] æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ä¿¡æ¯: {e}")

    time.sleep(0.3)  # ä¿æŒä¼‘çœ 

    # --- 2. è·å–è°ƒç ”å…¬å‘Šï¼Œç”¨ç‹¬ç«‹çš„ try-except åŒ…è£¹ ---
    try:
        df_relations = ak.stock_zh_a_disclosure_relation_cninfo(symbol=symbol, start_date=start_date, end_date=end_date)
        if df_relations is not None and not df_relations.empty:
            df_relations['tag'] = 'è°ƒç ”æ´»åŠ¨'
            all_dfs.append(df_relations)
    except Exception as e:
        # è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„ä¸»è¦é—®é¢˜ç‚¹ï¼Œç°åœ¨å®ƒå¯ä»¥è¢«å®‰å…¨åœ°æ•è·è€Œä¸ä¼šä¸­æ–­æ•´ä¸ªæµç¨‹
        print(f"âš ï¸  è­¦å‘Šï¼šæ‹‰å– {symbol} [è°ƒç ”å…¬å‘Š] æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ä¿¡æ¯: {e}")

    # --- 3. å¦‚æœä¸¤ä¸ªæ¥å£éƒ½å¤±è´¥æˆ–æ²¡æ•°æ®ï¼Œåˆ™è¿”å› None ---
    if not all_dfs:
        return None

    # --- 4. åˆå¹¶æ‰€æœ‰æˆåŠŸè·å–çš„æ•°æ® ---
    combined_df = pd.concat(all_dfs, ignore_index=True)
    if combined_df.empty:
        return None

    combined_df.drop_duplicates(subset=['å…¬å‘Šé“¾æ¥'], keep='first', inplace=True)

    # --- 5. æ ‡å‡†åŒ–å¤„ç† (ä½¿ç”¨â€œå…¬å‘Šæ—¶é—´â€ï¼Œå› ä¸ºè¯Šæ–­ç»“æœè¯æ˜äº†å®ƒæ˜¯æ­£ç¡®çš„åˆ—å) ---
    combined_df.rename(columns={
        "ä»£ç ": "symbol",
        "ç®€ç§°": "short_name",
        "å…¬å‘Šæ ‡é¢˜": "title",
        "å…¬å‘Šæ—¶é—´": "ann_date",  # ä½¿ç”¨è¯Šæ–­æ¢é’ˆç¡®è®¤çš„æ­£ç¡®åˆ—å
        "å…¬å‘Šé“¾æ¥": "url",
    }, inplace=True)

    combined_df["symbol"] = combined_df["symbol"].astype(str)
    combined_df["ann_date"] = pd.to_datetime(combined_df["ann_date"]).dt.date

    final_columns = ["symbol", "short_name", "title", "ann_date", "url"]
    return combined_df.reindex(columns=final_columns)
# --- ä¸»æµç¨‹ (æ›´æ–°ä»¥ä½¿ç”¨ä¿®å¤åçš„å‡½æ•°) ---
def sync_all_disclosures():
    stock_df = get_stock_pool()
    today_str = datetime.now().strftime("%Y%m%d")
    print(f"ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰ç±»å‹å…¬å‘Šï¼Œå…± {len(stock_df)} åªè‚¡ç¥¨ï¼Œæˆªæ­¢æ—¥æœŸï¼š{today_str}")

    for idx, row in stock_df.iterrows():
        symbol = row["symbol"]
        list_date = row["list_date"]
        last_date = get_last_disclosure_date(symbol)

        if last_date:
            start_date = last_date.strftime("%Y%m%d")
        else:
            start_date = pd.to_datetime(list_date).strftime("%Y%m%d") if list_date else "20100101"

        if start_date > today_str:
            print(f"â­ï¸ {symbol} æ— éœ€æ›´æ–°")
            continue

        print(f"â¬‡ï¸ [{idx + 1}/{len(stock_df)}] {symbol} ä» {start_date} æ›´æ–°è‡³ {today_str}")

        # ä½¿ç”¨ç»Ÿä¸€çš„è·å–å‡½æ•°
        final_df = fetch_all_disclosures(symbol, start_date, today_str)

        if final_df is None or final_df.empty:
            print(f"âšªï¸ {symbol} åœ¨æ­¤æœŸé—´æ— æ–°å…¬å‘Šã€‚")
            time.sleep(1)
            continue

        try:
            final_df.to_sql("stock_disclosure", con=engine, index=False, if_exists="append")
            print(f"âœ… {symbol} æˆåŠŸå†™å…¥ {len(final_df)} æ¡æ–°å…¬å‘Šã€‚")
        except IntegrityError:
            # è¿™ä¸ªé”™è¯¯æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœä¸¤ä¸ªæ¥å£è¿”å›äº†ç›¸åŒçš„URLï¼Œå¹¶ä¸”æ•°æ®åº“æœ‰å”¯ä¸€çº¦æŸ
            print(f"âš ï¸ {symbol} çš„éƒ¨åˆ†å…¬å‘Šå·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼Œè·³è¿‡é‡å¤éƒ¨åˆ†ã€‚")
        except Exception as e:
            print(f"âŒ {symbol} å†™å…¥æ•°æ®åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

        time.sleep(1)

    print("ğŸ­ ç¡®ä¿ç´¢å¼•å·²åˆ›å»º...")
    Index("idx_disclosure_date", StockDisclosure.ann_date).create(bind=engine, checkfirst=True)
    Index("idx_disclosure_symbol", StockDisclosure.symbol).create(bind=engine, checkfirst=True)
    print("ğŸ‰ æ‰€æœ‰å…¬å‘ŠåŒæ­¥å®Œæˆï¼")


if __name__ == "__main__":
    sync_all_disclosures()