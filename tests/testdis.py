# scripts/sync_disclosure_data.py (å®Œæ•´é‡æ„ç‰ˆ)

import time
from datetime import datetime, timedelta

import akshare as ak
import pandas as pd
from sqlalchemy import Index
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import IntegrityError

from db.database import get_engine_instance
from db.models import StockList, StockDisclosure

# --- é…ç½® (ä¿æŒä¸å˜) ---
engine = get_engine_instance()
Session = sessionmaker(bind=engine)
logger = pd.options.mode.chained_assignment = None  # å¿½ç•¥pandasçš„é“¾å¼èµ‹å€¼è­¦å‘Š


# --- è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ---
def get_stock_pool() -> pd.DataFrame:
    session = Session()
    df = pd.read_sql("SELECT code AS symbol, list_date FROM stock_list", con=engine)
    session.close()
    return df


def get_last_disclosure_date(symbol: str) -> datetime.date:
    session = Session()
    last = (
        session.query(StockDisclosure)
        .filter_by(symbol=symbol)
        .order_by(StockDisclosure.ann_date.desc())
        .first()
    )
    session.close()
    return last.ann_date if last else None


# --- æ•°æ®è·å–å‡½æ•° (æ¨¡å—åŒ–) ---

def fetch_periodic_reports(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ã€æ¨¡å—ä¸€ã€‘è°ƒç”¨ AkShare è·å–å®šæœŸæŠ¥å‘Šã€æ—¥å¸¸ç»è¥ç­‰å…¬å‘Š
    """
    try:
        # æ³¨æ„ï¼šè¿™é‡Œçš„å‡½æ•°åæ˜¯ stock_disclosure_report_cninfo
        df = ak.stock_zh_a_disclosure_report_cninfo(
            symbol=symbol, market="æ²ªæ·±äº¬", category="",
            start_date=start_date, end_date=end_date,
        )
        if df.empty:
            return None
        # æ ‡å‡†åŒ–åˆ—åå’Œæ•°æ®ç±»å‹
        df.rename(columns={"ä»£ç ": "symbol", "ç®€ç§°": "short_name", "å…¬å‘Šæ ‡é¢˜": "title", "å…¬å‘Šæ—¶é—´": "ann_date",
                           "å…¬å‘Šé“¾æ¥": "url"}, inplace=True)
        df["symbol"] = df["symbol"].astype(str)
        df["ann_date"] = pd.to_datetime(df["ann_date"]).dt.date
        return df[["symbol", "short_name", "title", "ann_date", "url"]]
    except Exception as e:
        print(f"âŒ æ‹‰å– {symbol} [å®šæœŸæŠ¥å‘Š]å¤±è´¥: {e}")
        return None


def fetch_research_announcements(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ã€æ¨¡å—äºŒã€‘æ–°å¢çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨äºè·å–â€œè°ƒç ”â€ç›¸å…³å…¬å‘Š
    """
    try:
        # æ³¨æ„ï¼šè¿™é‡Œçš„å‡½æ•°åæ˜¯ stock_zh_a_disclosure_relation_cninfo
        df = ak.stock_zh_a_disclosure_relation_cninfo(
            symbol=symbol, market="æ²ªæ·±äº¬",
            start_date=start_date, end_date=end_date,
        )
        if df.empty:
            return None
        # åŒæ ·è¿›è¡Œæ ‡å‡†åŒ–ï¼Œç¡®ä¿ä¸¤ä¸ªå‡½æ•°çš„è¾“å‡ºæ ¼å¼å®Œå…¨ä¸€è‡´
        df.rename(columns={"ä»£ç ": "symbol", "ç®€ç§°": "short_name", "å…¬å‘Šæ ‡é¢˜": "title", "å…¬å‘Šæ—¶é—´": "ann_date",
                           "å…¬å‘Šé“¾æ¥": "url"}, inplace=True)
        df["tag"] = "è°ƒç ”"
        df["symbol"] = df["symbol"].astype(str)
        df["ann_date"] = pd.to_datetime(df["ann_date"]).dt.date
        return df[["symbol", "short_name", "title", "ann_date", "url"]]
    except Exception as e:
        print(f"âŒ æ‹‰å– {symbol} [è°ƒç ”å…¬å‘Š]å¤±è´¥: {e}")
        return None


# --- ä¸»æµç¨‹ ---

def sync_all_disclosures():
    stock_df = get_stock_pool()
    today_str = datetime.now().strftime("%Y%m%d")
    print(f"ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰ç±»å‹å…¬å‘Šï¼Œå…± {len(stock_df)} åªè‚¡ç¥¨ï¼Œæˆªæ­¢æ—¥æœŸï¼š{today_str}")

    for idx, row in stock_df.iterrows():
        symbol = row["symbol"]
        list_date = row["list_date"]
        last_date = get_last_disclosure_date(symbol)

        if last_date:
            start_date = (last_date + timedelta(days=1)).strftime("%Y%m%d")
        else:
            start_date = pd.to_datetime(list_date).strftime("%Y%m%d") if list_date else "20100101"

        if start_date > today_str:
            print(f"â­ï¸ {symbol} æ— éœ€æ›´æ–°")
            continue

        print(f"â¬‡ï¸ [{idx + 1}/{len(stock_df)}] {symbol} ä» {start_date} æ›´æ–°è‡³ {today_str}")

        # 1. åˆ†åˆ«è·å–ä¸¤ç§ç±»å‹çš„å…¬å‘Š
        df_reports = fetch_periodic_reports(symbol, start_date, today_str)
        time.sleep(0.5)  # çŸ­æš‚ä¼‘çœ 
        df_research = fetch_research_announcements(symbol, start_date, today_str)

        # 2. åˆå¹¶ç»“æœ
        combined_df = pd.concat([df_reports, df_research], ignore_index=True)

        if combined_df.empty:
            print(f"âšªï¸ {symbol} åœ¨æ­¤æœŸé—´æ— æ–°å…¬å‘Šã€‚")
            time.sleep(1)
            continue

        # 3. å»é‡ï¼šé˜²æ­¢ä¸¤ä¸ªæ¥å£è¿”å›ç›¸åŒå…¬å‘Šï¼Œæˆ–ä¸æ•°æ®åº“ä¸­å·²æœ‰æ•°æ®é‡å¤
        combined_df.drop_duplicates(subset=['url'], keep='first', inplace=True)

        # 4. å†™å…¥æ•°æ®åº“
        try:
            combined_df.to_sql("stock_disclosure", con=engine, index=False, if_exists="append")
            print(f"âœ… {symbol} æˆåŠŸå†™å…¥ {len(combined_df)} æ¡æ–°å…¬å‘Šã€‚")
        except IntegrityError:
            print(f"âš ï¸ {symbol} çš„éƒ¨åˆ†å…¬å‘Šå·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼Œè·³è¿‡é‡å¤éƒ¨åˆ†ã€‚è¿™æ˜¯æ­£å¸¸ç°è±¡ã€‚")
        except Exception as e:
            print(f"âŒ {symbol} å†™å…¥æ•°æ®åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

        time.sleep(1)

    print("ğŸ­ ç¡®ä¿ç´¢å¼•å·²åˆ›å»º...")
    Index("idx_disclosure_date", StockDisclosure.ann_date).create(bind=engine, checkfirst=True)
    Index("idx_disclosure_symbol", StockDisclosure.symbol).create(bind=engine, checkfirst=True)
    print("ğŸ‰ æ‰€æœ‰å…¬å‘ŠåŒæ­¥å®Œæˆï¼")


if __name__ == "__main__":
    sync_all_disclosures()